{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6460d2b9d26b1e20",
   "metadata": {},
   "source": [
    "# Chapter 7: Advantage examples of Bayesian stats. \n",
    "\n",
    "Suggested topics: \n",
    "    - Bayesian Billiards game \n",
    "    - Rejecting outliers with MCMC \n",
    "Idea: create simulation of BB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4d099-5767-43aa-9198-15c39a54d8a1",
   "metadata": {},
   "source": [
    "# Bayesian Billiards\n",
    "A famous thought experiment comparing Bayesian and frequentist estimators is the 'Bayesian billiards'.\n",
    "\n",
    "Suppose we have a rectangular billiard table with length $L$. We throw one black ball on the table, which will bounce around until it stops, at a random $x$-coordinate of the table, and call this $z$, $0\\leq z\\leq L$. For the purposes of this thought experiment, suppose we don't know $z$, and want to estimate it. We could do this by throwing $n$ white balls onto the table, and seeing whether the end up to the left, or to the right of the black ball. By counting how many are to each side, we can reasonably 'guess' the value of $z$. To make the notation easier, suppose $L=1$. \n",
    "\n",
    "Note that one white ball is to the left of the black one with probability $z$, and to the right with probability $1-z$. The random variable \n",
    "$$\n",
    "X_i=\n",
    "\\begin{cases}\n",
    "1 &\\text{ if ball $i$ is to the left}\\\\\n",
    "0 &\\text{if ball $i$ is to the right}\n",
    "\\end{cases}\n",
    "$$\n",
    "is then a Bernoulli random variable with parameter $z$. \n",
    "The probability density is $f_{z}(X_i)=(1-z)^{1-X_i}+z^{X_i}$. \n",
    "The observations $X_1,\\ldots,X_n$ are an i.i.d. sample, and the log-likelihood is\n",
    "$$\\ell(z)\n",
    "=\n",
    "\\log(1-z)(n-\\sum_{i=1}^n X_i)\n",
    "+\\log(z)\\sum_{i=1}^nX_i .\n",
    "$$\n",
    "Setting the derivative of the log-likelihood equal to 0 gives\n",
    "$$\n",
    "\\frac{\\text{d}\\ell(z)}{\\text{d}z}\n",
    "=\n",
    "-\\frac{n-\\sum_{i=1}^n X_i}{1-z}(1-z)\n",
    "+\n",
    "\\frac{\\sum_{i=1}^n X_i}{z}\n",
    "=\n",
    "0,\n",
    "$$\n",
    "which gives us the following the frequentist MLE:\n",
    "$$\n",
    "\\hat z_{\\text{MLE}}\n",
    "=\n",
    "\\frac{\\sum_{i=1}^n X_i}{n}=\\overline{X}.\n",
    "$$\n",
    "So if exactly half of the $n$ white balls lie to the right, the estimate is \n",
    "$\\hat z_{\\text{MLE}}=1/2$,\n",
    "which is to be expected. \n",
    "But if all of the balls lie to the right, the estimate becomes $\\hat z_{\\text{MLE}}=0$, which means that the black ball would lie on the left edge.\n",
    "Intuitively, however, we expect the ball to lie a little to the side, depending on $n$. \n",
    "\n",
    "Now consider the Bayesian framework. \n",
    "The prior of $Z$ is the uniform distribution between 0 and 1, which just has density $\\pi(x)=1$ for all $0\\leq x\\leq1$.\n",
    "(The rest I'll finish later.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
