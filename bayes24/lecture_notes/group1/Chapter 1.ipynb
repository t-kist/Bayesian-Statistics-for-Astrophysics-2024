{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chapter 1: Hypothesis Testing & Maximum Likelihood"
   ],
   "id": "15986c3a895a01a7"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": [
    "In this chapter we'll explore hypothesis testing.\n",
    "- Hypothesis testing including (Yannick):\n",
    "    - p-values\n",
    "    - pro's and cons\n",
    "- Maximum likelihood including (Sander en Olivier):\n",
    "    - Connection to least-squares\n",
    "    - Connection to generative model (e.g., Hogg et al. article)\n",
    "    - Confidence intervals (\"a frequentist recipe\")"
   ],
   "id": "283ccdf132b170ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "A **hypothesis** is a statement regarding a population parameter. The hypothesis test is used to make a decision, based on a sample from the population, which of the hypotheses is true; either the **Nullhypothesis** or the **Alternative hypothesis**.\n",
    "\n",
    "The null hypothesis is the default assumption that there is no relationship between two measured phenomena and is denoted as $H_0$. The alternative hypothesis is the complement of the null hypothesis and is denoted as $H_1$. Let us note this in a more formal mathematical manner.\n",
    "\n",
    "Let $\\theta$ denote the hypothesis and let us partition the parameter space $\\Theta$ into two complementary sets, $\\Theta_0$ and $\\Theta_1$, such that $\\Theta_0$+$\\Theta_1$=$\\Theta$. The **hypothesis test** tests\n",
    "\n",
    "$$H_0:\\ \\theta\\in\\Theta_0\\ \\text{versus}\\ H_1:\\ \\theta\\in\\Theta_1.$$\n",
    "\n",
    "For example, $\\theta$ may characterize the shift in frequency of light due to differences in velocities of an observer and source (Doppler shift). A sceptical astronomer may be interested to see whether the Doppler shift exists or not. The null hypothesis may then be $H_0: \\theta = 0$, implying that there is no shift in frequency while the alternative hypothesis may be $H_1: \\theta \\neq 0$.\n",
    "\n",
    "Sticking with this example, if the sceptical astronomer researches this hypothesis thoroughly (with perfect equipment), they will of course find that $\\theta\\neq0$ since the Doppler effect exists. Hence, the astronomer should **reject** the Null hypothesis. Suppose the sceptical astronomer uses faulty equipment and finds $\\theta=0$, they should then (wrongfully) **retain** the Null hypothesis.\n",
    "\n",
    "This wrongful retention is one of the two errors that can be made in hypothesis testing. Them being a **type I error** and **type II error**. A type I error occurs when the Null hypothesis is rejected when in reality it is true. A type II error occurs when a Null hypothesis is accepted while in reality it is false. In the latter example the astronomer thus makes a type II error, since the Doppler effect is real and thus there *is* a shift in frequency implying that the Null hypothesis should be rejected. These errors have been summarized in the table below.\n",
    "\n",
    "<center>\n",
    "\n",
    "|                       | **Retain Null**   | **Reject Null**   |\n",
    "|-----------------------|-------------------|-------------------|\n",
    "| **H₀ true**           | Correct          | Type I error      |\n",
    "| **H₁ true**           | Type II error    | Correct           |\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "It should be noted that a null hypothesis can never be accepted. For that to happen, an infinite number of measurements must be made which is of course impossible. It is only possible to find evidence *against* the null hypothesis.\n",
    "\n",
    "To test a hypothesis a **Test Statistic (TS)** should be made. The test statistic is then used to measure the probability of a measurement outcome, given that the null hypothesis is *true*. This probability is also known as **the p-value** discussed in the next subsection.\n",
    "\n",
    "The test statistic can be any statistic that combines multiple **random variables** into a single number. This can be for example the median of a dataset, a likelihood ratio, etc. If the probability distribution of the test statistic is known from theory, a probability can be assigned to a given test statistic. If the probability distribution is unknown, **Monte Carlo simulations** can be used assuming $H_0$ is correct. More on this in chapter (HYPERREF NAAR HOOFDSTUK OVER MCMC).\n",
    "\n",
    "## p-values\n",
    "\n",
    "As briefly introduced in the previous subsection, the p-value can be defined as follows:\n",
    "\n",
    "$$\\boxed{\\textit{the p-value is the probability of measuring a dataset $X$ if the null hypothesis is correct.}}$$\n",
    "\n",
    "The p-value is derived from the test statistic which is some function that maps the dataset $X$ to a single value. More precisely, it is derived from the probability distribution of the test statistic known from theory or from a Monte Carlo simulation.\n",
    "\n",
    "The null hypothesis is rejected if the test statistic falls within a predetermined region, called the **rejection region**. Often in literature this rejection region is set at a value for the test statistic, such that the corresponding p-value is less than $0.05$. This limiting value is often called the **significance**.\n",
    "\n",
    "In scientific articles, often something along the lines of \"this null hypothesis is rejected at the $n\\ \\sigma$ level\" is stated. This simply means that the observed result is significant to a degree where the probability of it occurring due to random chance corresponds to a deviation of $n\\sigma$ from the mean of a normal distribution. For example: $1\\ \\sigma$ would correspond to a confidence level of $68.3\\%$, $3\\ \\sigma$ corresponds to $99.7\\%$, etc.\n",
    "\n",
    "## Advantages and Disadvantages of Hypothesis Testing\n",
    "\n",
    "The main advantage of hypothesis testing is that it provides a structured framework for decision-making. The steps of hypothesis testing are as follows:\n",
    "\n",
    "1.  Form a null and alternative hypothesis.\n",
    "\n",
    "2.  Define a test statistic $T$.\n",
    "\n",
    "3.  Find the probability distribution of the test statistic.\n",
    "\n",
    "4.  Compare the test statistic with the probability distribution to find the p-value.\n",
    "\n",
    "In addition, the concept of p-values is widely known across disciplines.\n",
    "\n",
    "Hypothesis testing has some notable downsides. One major issue is that statistical tests are often applied more than necessary. In many situations, confidence intervals or estimation methods might be more appropriate. If you don't have a clear, meaningful hypothesis, don't need to make a definitive yes-or-no decision, or aren't concerned about error probabilities, then hypothesis testing might not be the right approach for your needs.\n",
    "\n",
    "Another issue around p-values is the misinterpretation of them. The p-value is *not* the probability of $H_0$ being correct. This is a mistake often found in articles. It is strictly the probability of measuring a dataset $X$ *if* the null hypothesis is correct based on the defined test statistic (with explicit emphasis on the word *if*). The true definition of the p-value is thus a bit of an awkward one and should therefore be used with caution when communicating with a wider audience consisting of not only those educated in statistics.\n",
    "\n",
    "Scientific fields like psychology and medicine have faced a major challenge called the replication crisis due to this misinterpretation of p-values. Here, many high-profile findings couldn't be reproduced, even with large samples and identical methods. This revealed that a significant number of \"discoveries\\\" might actually be false positives, despite being widely accepted and forming the basis of extensive research. Several factors contribute to this problem, both unintentional and deliberate:\n",
    "\n",
    "1.  Multiple Testing: Many studies fail to account for the fact that testing multiple hypotheses increases the likelihood of false positives. This oversight is often due to inadequate education in statistics.\n",
    "\n",
    "2.  Publication Bias: Journals prioritize significant results, leading to the \"file drawer effect\\\", where studies with non-significant findings remain unpublished. As a result, the scientific record is biased toward positive results.\n",
    "\n",
    "3.  Incentives and Misconduct: Researchers may unintentionally or deliberately engage in practices like:\n",
    "\n",
    "    -   HARKing (Hypothesizing After Results are Known): Creating hypotheses based on the data after seeing the results, which undermines the validity of the conclusions.\n",
    "\n",
    "    -   p-hacking: Manipulating data or analysis (e.g., excluding outliers or changing variables) to achieve statistically significant results.\n",
    "\n",
    "These issues have started to gain attention in recent years, prompting efforts to improve research practices. While fields like astronomy and physics have been less affected, they are not immune. The lesson is clear: small shortcuts or biases can accumulate and harm the integrity of science.\n",
    "\n",
    "## Example: sceptical astronomer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e0b1dba74f7fa83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Maximum likelihood\n",
    "\n",
    "### Least-squares\n",
    "### Generative model\n",
    "### Confidence intervals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93cd3789e7e34283"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T13:01:39.252700Z",
     "start_time": "2024-11-05T13:01:39.248179Z"
    }
   },
   "id": "258f787934659727",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sources:**\n",
    "- Hogg et al. (2010) Data analysis recipes: Fitting a model to data\n",
    "- Statistical inference, Casella & Berger (2002)\n",
    "- Mathematical Statistics with Applications, Wackerly et al. (2008)\n",
    "- All of Statistics, Wasserman (2004)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bb6a9383e22b3ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T13:01:39.260832Z",
     "start_time": "2024-11-05T13:01:39.256610Z"
    }
   },
   "id": "d1523b11690190ef",
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
